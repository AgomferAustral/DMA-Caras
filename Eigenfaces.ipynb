{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgomferAustral/DMA-Caras/blob/main/Eigenfaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYbCH9LO3Acj",
        "outputId": "f7abf224-8ae7-4223-92c8-dcf9ceda0a89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Importacion de librerias\n",
        "#!pip install --upgrade mediapipe\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0ssP3bZH3dZR",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "e08e6428-cb00-4d5c-f2a5-ad8e5117d626"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'audio_classifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c49ad7155d6e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#!pip install --upgrade mediapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/audio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_embedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mAudioClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mAudioClassifierOptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifierOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mAudioClassifierResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifierResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "SEqwIhmUhJU9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "source": [
        "#!pip install --upgrade numpy\n",
        "#!pip install --upgrade scipy"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TyyBLLrOCOwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983cd1e8-81c0-47fc-96b9-b3592eaabc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.2.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "id": "V3pZH_qBIKzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Definicion de ruta de conexion\n",
        "ruta_entrada = '/content/drive/MyDrive/Eigenfaces'\n",
        "ruta_salida = '/content/drive/MyDrive/Eigenfaces70x70'"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_pFRsi5H3x0-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: verificar si la carpeta en \"ruta_salida\" existe. Si no existe, crearla\n",
        "\n",
        "if not os.path.exists(ruta_salida):\n",
        "  os.makedirs(ruta_salida)\n"
      ],
      "metadata": {
        "id": "R9Pq2yVfWQAE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def procesar_archivos_en_carpetas(ruta_principal,ruta_final):\n",
        "  \"\"\"Recorre las carpetas dentro de la ruta principal y procesa los archivos.\n",
        "\n",
        "  Args:\n",
        "    ruta_principal: La ruta de la carpeta principal.\n",
        "  \"\"\"\n",
        "  print(f\"Ruta principal: {ruta_principal}\")\n",
        "  for carpeta_actual, _, archivos in os.walk(ruta_principal):\n",
        "    print(f\"Carpeta actual: {carpeta_actual}\")\n",
        "    for archivo in archivos:\n",
        "      print(f\"Archivo: {archivo}\")\n",
        "      ruta_completa = os.path.join(carpeta_actual, archivo)\n",
        "      try:\n",
        "\n",
        "            img = cv2.imread(ruta_completa, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                print(f\"⚠️ No se pudo leer: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            # Detectar rostros\n",
        "            faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "            for i, (x, y, w, h) in enumerate(faces):\n",
        "                face = img[y:y+h, x:x+w]  # Recortar rostro\n",
        "                face_resized = cv2.resize(face, img_size)  # Redimensionar a 70x70\n",
        "\n",
        "                # Crear carpeta de salida manteniendo la estructura original\n",
        "                relative_path = os.path.relpath(carpeta_actual, ruta_entrada)\n",
        "                output_folder = os.path.join(ruta_salida, relative_path)\n",
        "                os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "                # Guardar rostro procesado\n",
        "                output_path = os.path.join(output_folder, f\"{os.path.splitext(file)[0]}_face{i}.jpg\")\n",
        "                cv2.imwrite(output_path, face_resized)\n",
        "                print(f\"✅ Guardado: {output_path}\")\n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"❌ Error procesando {ruta_completa}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"Error al procesar el archivo {ruta_completa}: {e}\")\n",
        "\n",
        "# Ejemplo de uso:\n",
        "print(\"Procesando archivos\")\n",
        "procesar_archivos_en_carpetas(ruta_entrada, ruta_salida)\n",
        "print(\"Proceso inicial terminado ...\")"
      ],
      "metadata": {
        "id": "-9otdo5QIG_W",
        "outputId": "8b36a56c-c931-44e0-e737-41035c89f3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando archivos\n",
            "Ruta principal: /content/drive/MyDrive/Eigenfaces\n",
            "Carpeta actual: /content/drive/MyDrive/Eigenfaces\n",
            "Carpeta actual: /content/drive/MyDrive/Eigenfaces/Noelia R\n",
            "Archivo: 1742907849929.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'img_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-27848ee3d159>\u001b[0m in \u001b[0;36mprocesar_archivos_en_carpetas\u001b[0;34m(ruta_principal, ruta_final)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Detectar rostros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaleFactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'face_cascade' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-27848ee3d159>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Ejemplo de uso:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Procesando archivos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mprocesar_archivos_en_carpetas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta_entrada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruta_salida\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Proceso inicial terminado ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-27848ee3d159>\u001b[0m in \u001b[0;36mprocesar_archivos_en_carpetas\u001b[0;34m(ruta_principal, ruta_final)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"❌ Error procesando {img_path}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CaIPvpaKVWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Deteccion de rostro\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2eEvLoB4IxM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "7a91483d-5d72-4284-b659-9fab61065396"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-714fa9b82da3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Deteccion de rostro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmp_face_detection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mface_detection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp_face_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaceDetection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_detection_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mp' is not defined"
          ]
        }
      ]
    },
    {
      "source": [
        "# Recortar imagenes\n",
        "imagenes_recortadas = []\n",
        "for imagen in imagenes:\n",
        "  # Convertir la imagen de escala de grises a RGB\n",
        "  imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "  # Detectar rostros en la imagen\n",
        "  results = face_detection.process(imagen_rgb)\n",
        "\n",
        "  # Si se encuentra al menos un rostro\n",
        "  if results.detections:\n",
        "    for detection in results.detections:\n",
        "      # Obtener la bounding box del rostro\n",
        "      bbox = detection.location_data.relative_bounding_box\n",
        "\n",
        "      # Calcular las coordenadas de la bounding box en píxeles\n",
        "      h, w = imagen.shape\n",
        "      x = int(bbox.xmin * w)\n",
        "      y = int(bbox.ymin * h)\n",
        "      width = int(bbox.width * w)\n",
        "      height = int(bbox.height * h)\n",
        "\n",
        "      # Recortar la imagen usando la bounding box\n",
        "      rostro_recortado = imagen[y:y+height, x:x+width]\n",
        "\n",
        "      # Añadir la imagen recortada a la lista\n",
        "      imagenes_recortadas.append(rostro_recortado)\n",
        "\n",
        "face_detection.close()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JszVubgKIzEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mostrar las primeras 5 imágenes recortadas\n",
        "for i in range(min(5, len(imagenes_recortadas))):\n",
        "    plt.imshow(imagenes_recortadas[i], cmap='gray')\n",
        "    plt.title(f\"Imagen recortada {i + 1}\")\n",
        "    plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Q87Mp2TFJO_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Escarlar imagenes\n",
        "tamaños_comunes = [(70, 70)]\n",
        "\n",
        "# Escalar las imágenes a cada tamaño común\n",
        "imagenes_escaladas = [cv2.resize(image, tamaños_comunes[0]) for image in imagenes_recortadas]\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3UTzXPE5q8o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar las primeras 10 imágenes escaladas\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2 filas, 5 columnas\n",
        "fig.suptitle(\"Primeras 10 Imágenes Escaladas\", fontsize=16)\n",
        "\n",
        "for i, imagen in enumerate(imagenes_escaladas[:10]):\n",
        "    ax = axes[i // 5, i % 5]  # Calcula la posición en la cuadrícula\n",
        "    ax.imshow(imagen, cmap='gray')  # Muestra la imagen en escala de grises\n",
        "    ax.set_title(f\"Imagen {i + 1}\")\n",
        "\n",
        "    # Agregar valores en los ejes\n",
        "    ax.set_xticks(np.arange(0, imagen.shape[1], 10))  # Marcas cada 10 píxeles en el eje x\n",
        "    ax.set_yticks(np.arange(0, imagen.shape[0], 10))  # Marcas cada 10 píxeles en el eje y\n",
        "    ax.set_xticklabels(np.arange(0, imagen.shape[1], 10))  # Etiquetas cada 10 píxeles en el eje x\n",
        "    ax.set_yticklabels(np.arange(0, imagen.shape[0], 10))  # Etiquetas cada 10 píxeles en el eje y\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SOh5X91grQl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Crecion de matris 2D\n",
        "\n",
        "\n",
        "# Crear la matriz de datos\n",
        "m = len(imagenes_escaladas)\n",
        "d = tamaños_comunes[0][0] * tamaños_comunes[0][1]\n",
        "X = np.reshape(imagenes_escaladas, (m, d))\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fcb1I9pjs1fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Obtencion de componentes principales\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Aplicar SVD\n",
        "U, Sigma, VT = np.linalg.svd(X, full_matrices=False)\n",
        "\n",
        "# Aplicar PCA usando SVD\n",
        "pca = PCA(n_components=50)  # Reducir a x componentes principales\n",
        "pca.fit(X)  # Ajustar PCA a la matriz de datos\n",
        "componentes_principales = pca.transform(X) # Transformar los datos\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "vMGE-XBBvlBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OF9zCZGoKW4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ReC9jObcKW7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sJ4GpB6dKW-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento de imagenes\n",
        "\n",
        "##  "
      ],
      "metadata": {
        "id": "lBNvKCYeKac9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "254R6KynKXBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pKOmsfSKXEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHM-r5ruKXHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgieoLIbKXKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9P1vAjTiKXNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "is6fxzGaKXQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ewAq73H4KXTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v21S8MSWKXWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iRVnN4HErQUi"
      }
    }
  ]
}