{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgomferAustral/DMA-Caras/blob/main/EigenfacesMZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYbCH9LO3Acj",
        "outputId": "157abcb3-50de-4cd3-9a6b-843fc3b702f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/.drive; to attempt to forcibly remount, call drive.mount(\"/content/.drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VPjbbfWMGUMS",
        "outputId": "4f352760-c994-4893-8bbf-ce0acf67ec45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Importacion de librerias\n",
        "import mediapipe as mp"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0ssP3bZH3dZR",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "SEqwIhmUhJU9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade scipy"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TyyBLLrOCOwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade mediapipe"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V3pZH_qBIKzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Definicion de ruta de conexion\n",
        "ruta_imagenes = '/content/.drive/My Drive/Eigenfaces'"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_pFRsi5H3x0-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def procesar_archivos_en_carpetas(ruta_principal):\n",
        "  \"\"\"Recorre las carpetas dentro de la ruta principal y procesa los archivos.\n",
        "\n",
        "  Args:\n",
        "    ruta_principal: La ruta de la carpeta principal.\n",
        "  \"\"\"\n",
        "  print(f\"Ruta principal: {ruta_principal}\")\n",
        "  for carpeta_actual, _, archivos in os.walk(ruta_principal):\n",
        "    print(f\"Carpeta actual: {carpeta_actual}\")\n",
        "    for archivo in archivos:\n",
        "      print(f\"Archivo: {archivo}\")\n",
        "      ruta_completa = os.path.join(carpeta_actual, archivo)\n",
        "      try:\n",
        "        # Aquí va el código para procesar el archivo\n",
        "        # Por ejemplo, leer el archivo y realizar alguna operación\n",
        "        with open(ruta_completa, 'r') as f:\n",
        "          contenido = f.read()\n",
        "          print(f\"Contenido del archivo {ruta_completa}:\\n{contenido}\")\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"Error al procesar el archivo {ruta_completa}: {e}\")\n",
        "\n",
        "# Ejemplo de uso:\n",
        "print(\"Procesando archivos\")\n",
        "procesar_archivos_en_carpetas(ruta_imagenes)\n",
        "print(\"Proceso inicial terminado ...\")"
      ],
      "metadata": {
        "id": "-9otdo5QIG_W",
        "outputId": "1fd8da8e-4048-4d54-e6d5-7fc5096b353b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando archivos\n",
            "Proceso inicial terminado ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CaIPvpaKVWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRXwLvFkIGfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Carga de imagenes\n",
        "imagenes = []\n",
        "for nombre_archivo in os.listdir(ruta_imagenes):\n",
        "       ruta_imagen = os.path.join(ruta_imagenes, nombre_archivo)\n",
        "       imagen = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)  # Carga en escala de grises\n",
        "       imagenes.append(imagen)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3t7JzwBY5r4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "print(f\"Se cargaron {len(imagenes)} imágenes.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_yl9J-HV6jv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Mostrar imagenes importadas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mostrar las primeras 5 imágenes\n",
        "for i in range(min(5, len(imagenes))):\n",
        "    plt.imshow(imagenes[i], cmap='gray')\n",
        "    plt.title(f\"Imagen {i + 1}\")\n",
        "    plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sezC6asf_yYy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Deteccion de rostro\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2eEvLoB4IxM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Recortar imagenes\n",
        "imagenes_recortadas = []\n",
        "for imagen in imagenes:\n",
        "  # Convertir la imagen de escala de grises a RGB\n",
        "  imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "  # Detectar rostros en la imagen\n",
        "  results = face_detection.process(imagen_rgb)\n",
        "\n",
        "  # Si se encuentra al menos un rostro\n",
        "  if results.detections:\n",
        "    for detection in results.detections:\n",
        "      # Obtener la bounding box del rostro\n",
        "      bbox = detection.location_data.relative_bounding_box\n",
        "\n",
        "      # Calcular las coordenadas de la bounding box en píxeles\n",
        "      h, w = imagen.shape\n",
        "      x = int(bbox.xmin * w)\n",
        "      y = int(bbox.ymin * h)\n",
        "      width = int(bbox.width * w)\n",
        "      height = int(bbox.height * h)\n",
        "\n",
        "      # Recortar la imagen usando la bounding box\n",
        "      rostro_recortado = imagen[y:y+height, x:x+width]\n",
        "\n",
        "      # Añadir la imagen recortada a la lista\n",
        "      imagenes_recortadas.append(rostro_recortado)\n",
        "\n",
        "face_detection.close()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JszVubgKIzEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mostrar las primeras 5 imágenes recortadas\n",
        "for i in range(min(5, len(imagenes_recortadas))):\n",
        "    plt.imshow(imagenes_recortadas[i], cmap='gray')\n",
        "    plt.title(f\"Imagen recortada {i + 1}\")\n",
        "    plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Q87Mp2TFJO_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Escarlar imagenes\n",
        "tamaños_comunes = [(70, 70)]\n",
        "\n",
        "# Escalar las imágenes a cada tamaño común\n",
        "imagenes_escaladas = [cv2.resize(image, tamaños_comunes[0]) for image in imagenes_recortadas]\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3UTzXPE5q8o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar las primeras 10 imágenes escaladas\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2 filas, 5 columnas\n",
        "fig.suptitle(\"Primeras 10 Imágenes Escaladas\", fontsize=16)\n",
        "\n",
        "for i, imagen in enumerate(imagenes_escaladas[:10]):\n",
        "    ax = axes[i // 5, i % 5]  # Calcula la posición en la cuadrícula\n",
        "    ax.imshow(imagen, cmap='gray')  # Muestra la imagen en escala de grises\n",
        "    ax.set_title(f\"Imagen {i + 1}\")\n",
        "\n",
        "    # Agregar valores en los ejes\n",
        "    ax.set_xticks(np.arange(0, imagen.shape[1], 10))  # Marcas cada 10 píxeles en el eje x\n",
        "    ax.set_yticks(np.arange(0, imagen.shape[0], 10))  # Marcas cada 10 píxeles en el eje y\n",
        "    ax.set_xticklabels(np.arange(0, imagen.shape[1], 10))  # Etiquetas cada 10 píxeles en el eje x\n",
        "    ax.set_yticklabels(np.arange(0, imagen.shape[0], 10))  # Etiquetas cada 10 píxeles en el eje y\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SOh5X91grQl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Crecion de matris 2D\n",
        "\n",
        "\n",
        "# Crear la matriz de datos\n",
        "m = len(imagenes_escaladas)\n",
        "d = tamaños_comunes[0][0] * tamaños_comunes[0][1]\n",
        "X = np.reshape(imagenes_escaladas, (m, d))\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fcb1I9pjs1fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Obtencion de componentes principales\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Aplicar SVD\n",
        "U, Sigma, VT = np.linalg.svd(X, full_matrices=False)\n",
        "\n",
        "# Aplicar PCA usando SVD\n",
        "pca = PCA(n_components=50)  # Reducir a x componentes principales\n",
        "pca.fit(X)  # Ajustar PCA a la matriz de datos\n",
        "componentes_principales = pca.transform(X) # Transformar los datos\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "vMGE-XBBvlBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OF9zCZGoKW4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ReC9jObcKW7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sJ4GpB6dKW-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento de imagenes\n",
        "\n",
        "##  "
      ],
      "metadata": {
        "id": "lBNvKCYeKac9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "254R6KynKXBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pKOmsfSKXEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHM-r5ruKXHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgieoLIbKXKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9P1vAjTiKXNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "is6fxzGaKXQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ewAq73H4KXTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v21S8MSWKXWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iRVnN4HErQUi"
      }
    }
  ]
}